from flask import Flask, request, jsonify, render_template
import pickle
from dotenv import load_dotenv
import os
import google.generativeai as genai  # Correct SDK for Gemini

# ğŸ“‚ Load environment variables
load_dotenv()

# ğŸ”‘ Load Google Gemini API Key
GEMINI_API_KEY = os.getenv("GOOGLE_AI_STUDIO")

# âš ï¸ Check if the API Key is loaded
if not GEMINI_API_KEY:
    raise ValueError("âŒ ERROR: Gemini API Key not found. Check your .env file.")
else:
    print("âœ… Gemini API Key Loaded.")

# ğŸš€ Configure Gemini API
genai.configure(api_key=GEMINI_API_KEY)

# ğŸ·ï¸ Initialize Flask app
app = Flask(__name__)

# ğŸ“¦ Load trained Titanic model
with open("titanic_model.pkl", "rb") as f:
    model = pickle.load(f)

# ğŸ§  Initialize Gemini model (fast or pro)
gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')  # Use 'gemini-pro' for more depth

# ğŸ”® Function to generate explanation using Gemini
def get_gemini_explanation(pclass, sex, age, prediction):
    prediction_text = "sobreviviÃ³" if prediction == 1 else "no sobreviviÃ³"
    sex_text = "femenino" if sex == 1 else "masculino"

    # ğŸ“– Dynamic prompt
    prompt = (
        "Eres un historiador experto en el Titanic y tienes acceso a un modelo de Machine Learning que predice la supervivencia de los pasajeros. "
        "Utilizando las siguientes caracterÃ­sticas, explica de forma lÃ³gica y detallada por quÃ© este pasajero habrÃ­a sobrevivido o no:\n\n"
        f"ğŸ›³ï¸ **Datos del pasajero:**\n"
        f"- Clase: {pclass}\n"
        f"- GÃ©nero: {sex_text}\n"
        f"- Edad: {age} aÃ±os\n"
        f"- PredicciÃ³n del modelo: {prediction_text}\n\n"
        "ğŸ“– **Instrucciones:**\n"
        "- Proporciona un anÃ¡lisis histÃ³rico y lÃ³gico basado en estos datos.\n"
        "- Relaciona la clase social y el acceso a los botes salvavidas.\n"
        "- SÃ© claro, conciso y profesional.\n\n"
        "ğŸ“¢ **ExplicaciÃ³n:**"
    )

    try:
        # ğŸ’¬ Generate explanation using Gemini
        response = gemini_model.generate_content(prompt)
        return response.text if response.text else "Sin explicaciÃ³n disponible."
    except Exception as e:
        return f"Error al obtener la explicaciÃ³n de la IA: {str(e)}"

# ğŸ  Home route
@app.route('/')
def home():
    return render_template('form.html')

# ğŸ“Š Prediction route (Form Submission)
@app.route('/predict_form', methods=['POST'])
def predict_form():
    try:
        # ğŸ“¥ Extract user inputs
        pclass = int(request.form['Pclass'])
        sex = 1 if request.form['Sex'] == 'female' else 0
        age = float(request.form['Age'])

        # ğŸ¤– Model Prediction
        input_data = [[pclass, sex, age]]
        prediction = model.predict(input_data)[0]
        result = "Â¡SobreviviÃ³! ğŸ‰" if prediction == 1 else "No sobreviviÃ³. ğŸ˜¢"

        # ğŸ”® Generate AI Explanation
        explanation = get_gemini_explanation(pclass, sex, age, prediction)

        return render_template('form.html', prediction=result, explanation=explanation)

    except Exception as e:
        return render_template('form.html', prediction=f"Error: {str(e)}")

# ğŸ”Œ API Prediction Route (For JSON Requests)
@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.json

        # ğŸ“¥ Extract data from JSON
        pclass = int(data.get('Pclass'))
        sex = 1 if data.get('Sex').lower() == 'female' else 0
        age = float(data.get('Age'))

        # ğŸ¤– Model Prediction
        input_data = [[pclass, sex, age]]
        prediction = model.predict(input_data)[0]

        # ğŸ”® Generate AI Explanation
        explanation = get_gemini_explanation(pclass, sex, age, prediction)

        return jsonify({
            "predicciÃ³n": "SobreviviÃ³" if prediction == 1 else "No sobreviviÃ³",
            "explicaciÃ³n": explanation
        })

    except Exception as e:
        return jsonify({"error": str(e)})

# ğŸ”¥ Run the app
if __name__ == "__main__":
    app.run(debug=True, host='0.0.0.0', port=int(os.environ.get('PORT', 5000)))

