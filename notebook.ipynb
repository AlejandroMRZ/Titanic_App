{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado y guardado como titanic_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(data, is_train=True):\n",
    "    # Select relevant columns for training/testing\n",
    "    columns = [\"Pclass\", \"Sex\", \"Age\"]\n",
    "    if is_train:\n",
    "        columns.append(\"Survived\")  # Include target only for training\n",
    "    \n",
    "    data = data[columns].dropna()\n",
    "    data[\"Sex\"] = data[\"Sex\"].map({\"male\": 0, \"female\": 1})  # Encode 'Sex'\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data = preprocess(train_data, is_train=True)\n",
    "test_data = preprocess(test_data, is_train=False)\n",
    "\n",
    "# Define features and target\n",
    "X_train = train_data[[\"Pclass\", \"Sex\", \"Age\"]]\n",
    "y_train = train_data[\"Survived\"]\n",
    "\n",
    "X_test = test_data[[\"Pclass\", \"Sex\", \"Age\"]]\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# (Optional) Predict on test data\n",
    "# Since `test.csv` has no 'Survived' column, predictions can't be evaluated but can be saved\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"titanic_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Modelo entrenado y guardado como titanic_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key Loaded: AIzaS*****\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file from the current directory\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key\n",
    "GOOGLE_AI_STUDIO = os.getenv(\"GOOGLE_AI_STUDIO\")\n",
    "\n",
    "# Debugging output\n",
    "if GOOGLE_AI_STUDIO:\n",
    "    print(\"✅ API Key Loaded:\", GOOGLE_AI_STUDIO[:5] + \"*****\")\n",
    "else:\n",
    "    print(\"❌ ERROR: API key not loaded. Check the .env file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key Loaded: AIzaS*****\n",
      "\n",
      "Texto Generado:\n",
      " Claro, aquí tienes un breve poema sobre la lluvia:\n",
      "\n",
      "El cielo llora, las nubes se abren,\n",
      "Gotas suaves caen, la tierra bebe.\n",
      "Un ritmo tranquilo, un suave murmullo,\n",
      "La lluvia lava, todo se renueva.\n",
      "\n",
      "Texto Generado:\n",
      " La capital de Francia es **París**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_AI_STUDIO\")\n",
    "\n",
    "# Verificar que se haya cargado la API key\n",
    "if not api_key:\n",
    "    print(\"❌ API Key NOT Loaded. Please check your .env file.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"✅ API Key Loaded:\", api_key[:5] + \"*****\")\n",
    "\n",
    "# Configurar la API key de Google AI\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Definir el modelo a utilizar\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-exp') # O 'gemini-pro' para el modelo pro\n",
    "\n",
    "\n",
    "# Función para generar texto\n",
    "def generate_text(prompt,\n",
    "                 temperature=0.9,\n",
    "                 top_p=1.0,\n",
    "                 top_k=40,\n",
    "                 max_output_tokens=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Genera texto utilizando el modelo Gemini.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): El texto inicial o prompt para guiar la generación.\n",
    "        temperature (float, optional): Controla la aleatoriedad de la generación. \n",
    "            Valores más altos (e.g., 1.0) hacen que el texto sea más diverso e impredecible.\n",
    "            Valores más bajos (e.g., 0.2) hacen que el texto sea más determinista. \n",
    "            Por defecto es 0.9.\n",
    "        top_p (float, optional): El umbral para la selección de tokens. \n",
    "            Se eligen tokens con una probabilidad acumulada menor o igual a top_p.\n",
    "            Por defecto es 1.0 (selecciona todos los tokens posibles).\n",
    "        top_k (int, optional): El número máximo de tokens a considerar para la selección en cada paso. \n",
    "            Por defecto es 40.\n",
    "        max_output_tokens (int, optional): El número máximo de tokens que se generarán.\n",
    "            Si es None, el modelo usará un límite predeterminado.\n",
    "\n",
    "    Returns:\n",
    "        str: El texto generado por el modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "         response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "               temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                top_k=top_k,\n",
    "                max_output_tokens=max_output_tokens\n",
    "            )\n",
    "        )\n",
    "         return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error during text generation: {e}\"\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == '__main__':\n",
    "    prompt_text = \"\"\n",
    "    generated_text = generate_text(prompt_text, temperature = 0.5)\n",
    "    print(\"\\nTexto Generado:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Using cached google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.159.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from google-generativeai) (5.29.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from google-generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Using cached proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex_\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio-1.69.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Using cached google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "Using cached google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "Using cached google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading google_api_python_client-2.159.0-py2.py3-none-any.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 5.0/12.8 MB 27.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.8 MB 30.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 28.7 MB/s eta 0:00:00\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.69.0-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.69.0-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 29.4 MB/s eta 0:00:00\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, pyasn1, proto-plus, httplib2, grpcio, googleapis-common-protos, rsa, pyasn1-modules, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.68.1\n",
      "    Uninstalling grpcio-1.68.1:\n",
      "      Successfully uninstalled grpcio-1.68.1\n",
      "Successfully installed google-ai-generativelanguage-0.6.10 google-api-core-2.24.0 google-api-python-client-2.159.0 google-auth-2.37.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.69.0 grpcio-status-1.69.0 httplib2-0.22.0 proto-plus-1.25.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
